from langchain_huggingface import HuggingFacePipeline
import streamlit as st
import os
import requests
import shutil
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import Docx2txtLoader
from langchain_community.document_loaders import UnstructuredExcelLoader
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_experimental.text_splitter import SemanticChunker
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain import hub
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
import time
import tempfile
import urllib.parse
import zipfile
from langchain_core.runnables import RunnableLambda
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer




st.set_page_config(
    page_title="Trá»£ LÃ½ AI Tiáº¿ng Viá»‡t",
    page_icon="ğŸ¤–",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
  .main-header{
    text-align: center;
    padding: 1rem 0;
    margin-bottom: 2rem;
    background: linear-gradient(90deg, #ff0000, #ffff00);
    border-radius: 10px;
    color: white;
  }
  .chat-container{
    max-width: 800px;
    margin: 0 auto;
    padding: 1rem;
    max-height: 500px;
    overflow-y: auto;
    border: 1px solid #e0e0e0;
    border-radius: 10px;
    margin-bottom: 20px;
    background-color: #fafafa;
  }
  .user-message{
    background-color: #000000;
    color: #ffffff;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-left: 20%;
    text-align: left;
    border: 1px solid #333333;
  }
  .assistant-message{
    background-color: #006400;
    color: #ffffff;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-right: 20%;
    text-align: left;
    border: 1px solid #228b22;
  }
  .chat-input-container {
    position: sticky;
    bottom: 0;
    background-color: white;
    padding: 1rem;
    border-top: 2px solid #e0e0e0;
    border-radius: 10px;
    margin-top: 20px;
  }
  .stTextInput > div > div > input {
    border-radius: 25px;
    border: 2px solid #e0e0e0;
    padding: 12px 20px;
    font-size: 16px;
  }
  .document-info {
    background-color: #f8f9fa;
    border-left: 4px solid #28a745;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
  }
  .status-indicator{
    display: inline-block;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    margin-right: 8px;
  }
  .status-ready{
    background-color: #28a745;
  }
  .status-loading {
    background-color: #ffc107;
  }
  .status-error {
    background-color: #dc3545;
  }
  .thinking-indicator {
    background-color: #f5f5f5;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-right: 20%;
    text-align: left;
    border: 1px solid #ddd;
    animation: pulse 1.5s ease-in-out infinite;
  }
  @keyframes pulse {
    0% { opacity: 0.6; }
    50% { opacity: 1; }
    100% { opacity: 0.6; }
  }
  .upload-section {
    background-color: #f8f9fa;
    border: 2px dashed #28a745;
    border-radius: 10px;
    padding: 20px;
    margin: 10px 0;
    text-align: center;
  }
  .file-counter {
    background-color: #e3f2fd;
    border-radius: 5px;
    padding: 5px 10px;
    margin: 5px;
    display: inline-block;
    font-size: 12px;
  }
  .vietnam-flag {
    background: #da020e;
    width: 40px;
    height: 28px;
    display: inline-block;
    margin-right: 10px;
    border-radius: 3px;
    position: relative;
  }
  .vietnam-flag::after {
    content: "â­";
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    color: #ffcd00;
    font-size: 16px;
  }
</style>
""", unsafe_allow_html=True)

# Khá»Ÿi táº¡o session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'rag_chain' not in st.session_state:
    st.session_state.rag_chain = None
if 'documents_loaded' not in st.session_state:
    st.session_state.documents_loaded = False
if 'pdf_source' not in st.session_state:
    st.session_state.pdf_source = "github"
if 'github_repo_url' not in st.session_state:
    st.session_state.github_repo_url = "https://github.com/Jennifer1907/Time-Series-Team-Hub/tree/main/assets/pdf"
if 'local_folder_path' not in st.session_state:
    st.session_state.local_folder_path = "./knowledge_base"
if 'processing_query' not in st.session_state:
    st.session_state.processing_query = False
if 'query_input' not in st.session_state:
    st.session_state.query_input = ""

# Check if models downloaded or not
if 'models_loaded' not in st.session_state:
    st.session_state.models_loaded = False

# save downloaded embeding model
if 'embeddings' not in st.session_state:
    st.session_state.embeddings = None

# Save downloaded LLM
if 'llm' not in st.session_state:
    st.session_state.llm = None

# Import file processing function from process_file.py
from process_file import *
from load_llm import *

def format_docs(docs):
    if not docs:
        return "KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u liÃªn quan."
    return "\n\n".join(doc.page_content for doc in docs)



def create_rag_chain(all_documents):
    """Táº¡o chuá»—i RAG tá»« tÃ i liá»‡u"""
    if not all_documents:
        st.error("KhÃ´ng cÃ³ tÃ i liá»‡u nÃ o Ä‘á»ƒ xá»­ lÃ½")
        return None, 0

    try:
        st.info(f"ğŸ”„ Äang xá»­ lÃ½ {len(all_documents)} tÃ i liá»‡u...")

        # Kiá»ƒm tra ná»™i dung tÃ i liá»‡u
        total_text = ""
        for doc in all_documents:
            if hasattr(doc, 'page_content'):
                total_text += doc.page_content + "\n"

        if len(total_text.strip()) < 50:
            st.error("Ná»™i dung tÃ i liá»‡u quÃ¡ ngáº¯n hoáº·c khÃ´ng thá»ƒ Ä‘á»c Ä‘Æ°á»£c")
            return None, 0

        st.success(f"âœ… ÄÃ£ Ä‘á»c {len(total_text):,} kÃ½ tá»± tá»« tÃ i liá»‡u")

        # LÆ°u toÃ n bá»™ text vÃ o session state Ä‘á»ƒ fallback
        st.session_state.documents_text = total_text

        # Sá»­ dá»¥ng text splitter máº¡nh máº½ hÆ¡n náº¿u SemanticChunker tháº¥t báº¡i
        try:
            if st.session_state.embeddings:
                semantic_splitter = SemanticChunker(
                    embeddings=st.session_state.embeddings,
                    buffer_size=1,
                    breakpoint_threshold_type="percentile",
                    breakpoint_threshold_amount=95,
                    min_chunk_size=500,
                    add_start_index=True
                )
                docs = semantic_splitter.split_documents(all_documents)
                st.info(f"âœ… Sá»­ dá»¥ng SemanticChunker: {len(docs)} chunks")
            else:
                raise Exception("No embeddings available")
        except Exception as e:
            st.warning(f"SemanticChunker tháº¥t báº¡i: {str(e)}")
            st.info("ğŸ”„ Chuyá»ƒn sang RecursiveCharacterTextSplitter...")
            # Dá»± phÃ²ng vá»›i text splitter cÆ¡ báº£n
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len
            )
            docs = text_splitter.split_documents(all_documents)
            st.info(f"âœ… Sá»­ dá»¥ng RecursiveCharacterTextSplitter: {len(docs)} chunks")

        if not docs:
            st.error("KhÃ´ng cÃ³ Ä‘oáº¡n tÃ i liá»‡u nÃ o Ä‘Æ°á»£c táº¡o")
            # Táº¡o simple RAG chain vá»›i toÃ n bá»™ text
            def simple_rag_chain_text(question):
                return simple_text_retrieval(question, total_text)
            return simple_rag_chain_text, 1

        # Triá»ƒn khai FAISS vá»›i xá»­ lÃ½ lá»—i (chá»‰ khi cÃ³ embeddings)
        if st.session_state.embeddings:
            try:
                vector_db = FAISS.from_documents(documents=docs, embedding=st.session_state.embeddings)
                retriever = vector_db.as_retriever(top_k=5)
                st.success(f"âœ… ÄÃ£ táº¡o FAISS vector database vá»›i {len(docs)} chunks")
            except Exception as e:
                st.error(f"Lá»—i khi táº¡o FAISS vector database: {str(e)}")
                st.info("ğŸ”„ Chuyá»ƒn sang cháº¿ Ä‘á»™ tÃ¬m kiáº¿m text Ä‘Æ¡n giáº£n...")
                # Fallback to simple text search
                def simple_rag_chain_docs(question):
                    combined_text = "\n\n".join([doc.page_content for doc in docs])
                    return simple_text_retrieval(question, combined_text)
                return simple_rag_chain_docs, len(docs)
        else:
            st.info("ğŸ” KhÃ´ng cÃ³ embeddings, sá»­ dá»¥ng tÃ¬m kiáº¿m text Ä‘Æ¡n giáº£n")
            def simple_rag_chain_docs(question):
                combined_text = "\n\n".join([doc.page_content for doc in docs])
                return simple_text_retrieval(question, combined_text)
            return simple_rag_chain_docs, len(docs)

        # Sá»­ dá»¥ng tÃ¬m kiáº¿m tá»« khÃ³a thÃ´ng minh vá»›i hub prompt
        st.info("ğŸ” Sá»­ dá»¥ng tÃ¬m kiáº¿m tá»« khÃ³a thÃ´ng minh vá»›i RAG prompt")

        #? Code dÆ° thá»«a: prompt trong link rlm/rag-prompt vá»›i prompt cá»¥c bá»™ giá»‘ng nhau
        # Táº£i prompt tá»« hub
        # try:
        #     prompt = hub.pull("rlm/rag-prompt")
        #     st.success("âœ… ÄÃ£ táº£i prompt template tá»« hub")
        # except Exception as e:
        # st.warning(f"KhÃ´ng thá»ƒ táº£i prompt tá»« hub: {str(e)}")
        st.info("ğŸ”„ Sá»­ dá»¥ng prompt template cá»¥c bá»™...")

        # prompt = """Sá»­ dá»¥ng nhá»¯ng Ä‘oáº¡n ngá»¯ cáº£nh sau Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i á»Ÿ cuá»‘i.
        # Náº¿u báº¡n khÃ´ng biáº¿t cÃ¢u tráº£ lá»i, chá»‰ cáº§n nÃ³i ráº±ng báº¡n khÃ´ng biáº¿t, Ä‘á»«ng cá»‘ bá»‹a ra cÃ¢u tráº£ lá»i.
        # Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t.

        # Ngá»¯ cáº£nh: {context}

        # CÃ¢u há»i: {question}

        # Tráº£ lá»i:
        # """

        # prompt = """
        #     Dá»±a trÃªn cÃ¡c má»¥c ngá»¯ cáº£nh sau, vui lÃ²ng táº¡o má»™t cÃ¢u há»i tráº¯c nghiá»‡m liÃªn quan Ä‘áº¿n '{query}' vá» mÃ£ Python. CÃ¢u há»i pháº£i cÃ³ má»™t pháº§n thÃ¢n rÃµ rÃ ng vÃ  bá»‘n lá»±a chá»n: má»™t cÃ¢u tráº£ lá»i Ä‘Ãºng vÃ  ba cÃ¢u tráº£ lá»i sai nhÆ°ng cÃ³ váº» há»£p lÃ½. Äáº£m báº£o ráº±ng cÃ¢u tráº£ lá»i Ä‘Ãºng Ä‘Æ°á»£c há»— trá»£ trá»±c tiáº¿p bá»Ÿi ngá»¯ cáº£nh, vÃ  cÃ¡c cÃ¢u tráº£ lá»i sai cÃ³ liÃªn quan Ä‘áº¿n chá»§ Ä‘á» nhÆ°ng khÃ´ng Ä‘Ãºng dá»±a trÃªn ngá»¯ cáº£nh.

        #     HÆ°á»›ng dáº«n táº¡o cÃ¢u há»i:

        #         XÃ¡c Ä‘á»‹nh má»™t sá»± tháº­t hoáº·c thÃ´ng tin chÃ­nh tá»« ngá»¯ cáº£nh liÃªn quan Ä‘áº¿n '{query}' cÃ³ thá»ƒ Ä‘Æ°á»£c kiá»ƒm tra, cháº³ng háº¡n nhÆ° má»¥c Ä‘Ã­ch cá»§a má»™t hÃ m, giÃ¡ trá»‹ cá»§a má»™t biáº¿n hoáº·c Ä‘áº§u ra cá»§a má»™t Ä‘oáº¡n mÃ£.

        #         XÃ¢y dá»±ng pháº§n thÃ¢n cÃ¢u há»i má»™t cÃ¡ch rÃµ rÃ ng vÃ  cá»¥ thá»ƒ.

        #         Táº¡o bá»‘n lá»±a chá»n trong Ä‘Ã³ má»™t lá»±a chá»n lÃ  cÃ¢u tráº£ lá»i Ä‘Ãºng, vÃ  ba lá»±a chá»n cÃ²n láº¡i lÃ  há»£p lÃ½ nhÆ°ng khÃ´ng Ä‘Ãºng.

        #         Äáº£m báº£o ráº±ng táº¥t cáº£ cÃ¡c lá»±a chá»n cÃ³ Ä‘á»™ dÃ i vÃ  Ä‘á»‹nh dáº¡ng tÆ°Æ¡ng tá»± nhau.

        #         Ngáº«u nhiÃªn hÃ³a thá»© tá»± cÃ¡c lá»±a chá»n Ä‘á»ƒ cÃ¢u tráº£ lá»i Ä‘Ãºng khÃ´ng pháº£i lÃºc nÃ o cÅ©ng á»Ÿ cÃ¹ng má»™t vá»‹ trÃ­.

        #     TrÃ¬nh bÃ y cÃ¢u há»i cá»§a báº¡n theo Ä‘á»‹nh dáº¡ng nÃ y:

        #     CÃ¢u há»i: [pháº§n thÃ¢n cÃ¢u há»i]
        #     Lá»±a chá»n:
        #     A)[lá»±a chá»n 1]
        #     B)[lá»±a chá»n 2]
        #     C)[lá»±a chá»n 3]
        #     D)[lá»±a chá»n 4]
        #     ÄÃ¡p Ã¡n Ä‘Ãºng: [chá»¯ cÃ¡i cá»§a lá»±a chá»n Ä‘Ãºng]

        #     VÃ­ dá»¥ vá» má»™t cÃ¢u há»i tráº¯c nghiá»‡m tá»‘t:
        #     CÃ¢u há»i: Káº¿t quáº£ cá»§a print(2 + 3 * 4) trong Python sáº½ lÃ  gÃ¬?
        #     Lá»±a chá»n:
        #     A) 20
        #     B) 14
        #     C) 24
        #     D) 10
        #     ÄÃ¡p Ã¡n Ä‘Ãºng: B

        #     Ngá»¯ cáº£nh: {context}

        #     CÃ¢u há»i: {question}

        #     Tráº£ lá»i:

        # """ #? dÃ¹ng {{ }} Ä‘á»ƒ langchain khÃ´ng nháº­n string bÃªn trong {} lÃ  Biáº¿n


        prompt = """
            Báº¡n lÃ  má»™t trá»£ lÃ½ chuyÃªn táº¡o cÃ¢u há»i tráº¯c nghiá»‡m (MCQ).
            Má»—i cÃ¢u há»i gá»“m 1 cÃ¢u há»i (question), 4 lá»±a chá»n, cÃ²n Ä‘Æ°á»£c gá»i lÃ  choices (A, B, C, D), vÃ  chá»‰ 1 Ä‘Ã¡p Ã¡n Ä‘Ãºng, Ä‘Æ°á»£c gá»i lÃ  correct.
            ÄÃ¡p Ã¡n Ä‘Ãºng pháº£i Ä‘Æ°á»£c Ä‘Ã¡nh dáº¥u rÃµ.
            Náº¿u báº¡n khÃ´ng biáº¿t cÃ¢u tráº£ lá»i, chá»‰ cáº§n nÃ³i ráº±ng báº¡n khÃ´ng biáº¿t.

            Tráº£ vá» output dÆ°á»›i dáº¡ng JSON duy nháº¥t vá»›i Ä‘Ãºng bá»‘n khÃ³a. Chá»‰ xuáº¥t ra Ä‘á»‘i tÆ°á»£ng JSON, khÃ´ng thÃªm báº¥t ká»³ ná»™i dung nÃ o khÃ¡c.

            VÃ­ dá»¥ vá» Ä‘áº§u ra JSON:
            {{
                "question": "...",
                "choices": {{
                    "A": "...",
                    "B": "...",
                    "C": "...",
                    "D": "..."
                }},
                "correct": "...",
                "explanation": "..."
            }}

            Context: {context}
            Question: {question}


            HÃ£y táº¡o 1 cÃ¢u há»i tráº¯c nghiá»‡m bao gá»“m 4 lá»±a chá»n a) b) c) d) 
        """

        prompt_template = PromptTemplate(
            template=prompt,
            input_variables=["context", "question"]
        )


        rag_chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt_template
            | st.session_state.llm
            | StrOutputParser()
        )
        st.write(f"___[DEBUG]__\n")

        # Táº¡o simple RAG chain sá»­ dá»¥ng keyword search vá»›i prompt
        # def smart_rag_chain_with_prompt(question):
        #     try:
        #         # TÃ¬m tÃ i liá»‡u liÃªn quan báº±ng retriever
        #         relevant_docs = retriever.get_relevant_documents(question)
        #         context = format_docs(relevant_docs)

        #         # Sá»­ dá»¥ng simple text generation Ä‘á»ƒ tráº£ lá»i
        #         context = simple_text_retrieval(question, context)

        #         rag_chain = (
        #             {
        #                 "context": RunnableLambda(lambda _: context),
        #                 "question": RunnablePassthrough()
        #             }
        #             | prompt
        #             | st.session_state.llm
        #             | StrOutputParser()
        #         )

        #         return rag_chain

        #     except Exception as e:
        #         st.warning(f"Lá»—i retriever: {str(e)}, sá»­ dá»¥ng toÃ n bá»™ text")
        #         context = simple_text_retrieval(question, total_text)

        #         rag_chain = (
        #             {
        #                 "context": RunnableLambda(lambda _: context),
        #                 "question": RunnablePassthrough()
        #             }
        #             | prompt
        #             | st.session_state.llm
        #             | StrOutputParser()
        #         )
        #         st.write(f"[DEBUG] Lá»—i retriever fallback: {str(e)}")

        #         return rag_chain, len(docs)

        return rag_chain, len(docs) # basically return rag_chain, len(docs)

    except Exception as e:
        st.error(f"Lá»—i nghiÃªm trá»ng khi táº¡o chuá»—i RAG: {str(e)}")
        st.info("ğŸ”„ Táº¡o fallback RAG chain...")
        # Ultimate fallback
        def emergency_rag_chain(question):
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                return simple_text_retrieval(question, st.session_state.documents_text)
            else:
                return "Xin lá»—i, khÃ´ng thá»ƒ truy cáº­p ná»™i dung tÃ i liá»‡u. Vui lÃ²ng táº£i láº¡i tÃ i liá»‡u."
        return emergency_rag_chain, 1

def load_pdfs_from_github(repo_url):
    """Táº£i file PDF tá»« GitHub repository"""
    pdf_files = get_github_pdf_files(repo_url)

    if not pdf_files:
        st.warning("KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong GitHub repository")
        return None, 0, []

    temp_dir = tempfile.mkdtemp()
    all_documents = []
    loaded_files = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, pdf_file in enumerate(pdf_files):
        try:
            status_text.text(f"Äang táº£i vÃ  xá»­ lÃ½: {pdf_file['name']}")
            local_path = download_pdf_from_url(pdf_file['download_url'], pdf_file['name'], temp_dir)

            if local_path:
                loader = PyPDFLoader(local_path)
                documents = loader.load()
                all_documents.extend(documents)
                loaded_files.append(pdf_file['name'])

                st.success(f"âœ… ÄÃ£ xá»­ lÃ½: {pdf_file['name']} ({len(documents)} trang)")
            progress_bar.progress((i + 1) / len(pdf_files))
        except Exception as e:
            st.error(f"âŒ Lá»—i khi xá»­ lÃ½ {pdf_file['name']}: {str(e)}")

    progress_bar.empty()
    status_text.empty()

    # Dá»n dáº¹p thÆ° má»¥c táº¡m thá»i
    shutil.rmtree(temp_dir)

    if not all_documents:
        return None, 0, loaded_files

    rag_chain, num_chunks = create_rag_chain(all_documents)
    return rag_chain, num_chunks, loaded_files

def load_pdfs_from_folder(folder_path):
    """Táº£i táº¥t cáº£ file PDF tá»« thÆ° má»¥c Ä‘Æ°á»£c chá»‰ Ä‘á»‹nh"""
    cleaned_path = folder_path.strip().strip('"').strip("'")
    folder = Path(cleaned_path)

    if not folder.exists():
        st.error(f"âŒ ThÆ° má»¥c khÃ´ng tá»“n táº¡i: `{cleaned_path}`")
        return None, 0, []

    pdf_files = list(folder.glob("*.pdf"))
    if not pdf_files:
        st.warning(f"KhÃ´ng tÃ¬m tháº¥y file PDF nÃ o trong thÆ° má»¥c: {cleaned_path}")
        return None, 0, []

    all_documents = []
    loaded_files = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, pdf_file in enumerate(pdf_files):
        try:
            status_text.text(f"Äang xá»­ lÃ½: {pdf_file.name}")
            loader = PyPDFLoader(str(pdf_file))
            documents = loader.load()
            all_documents.extend(documents)
            loaded_files.append(pdf_file.name)
            progress_bar.progress((i + 1) / len(pdf_files))
            st.success(f"âœ… ÄÃ£ xá»­ lÃ½: {pdf_file.name} ({len(documents)} trang)")

        except Exception as e:
            st.error(f"âŒ Lá»—i khi xá»­ lÃ½ {pdf_file.name}: {str(e)}")

    progress_bar.empty()
    status_text.empty()

    if not all_documents:
        return None, 0, loaded_files

    rag_chain, num_chunks = create_rag_chain(all_documents)
    return rag_chain, num_chunks, loaded_files

def display_chat_message(message, is_user=True):
    """Hiá»ƒn thá»‹ tin nháº¯n trÃ² chuyá»‡n"""
    if is_user:
        st.markdown(f"""
        <div class="user-message">
            <strong style="color: #ffffff;">Báº¡n:</strong> <span style="color: #ffffff;">{message}</span>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="assistant-message">
            <strong style="color: #ffffff;">Trá»£ LÃ½ AI:</strong> <span style="color: #ffffff;">{message}</span>
        </div>
        """, unsafe_allow_html=True)

def display_thinking_indicator():
    """Hiá»ƒn thá»‹ chá»‰ bÃ¡o Ä‘ang suy nghÄ©"""
    st.markdown(f"""
    <div class="thinking-indicator">
        <strong>Trá»£ LÃ½ AI:</strong> ğŸ¤” Äang suy nghÄ©...
    </div>
    """, unsafe_allow_html=True)

#? rag_chain.invoke typeof function
def process_user_query(question):
    """Xá»­ lÃ½ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng"""
    try:
        if not st.session_state.rag_chain:
            return "Xin lá»—i, chÆ°a cÃ³ tÃ i liá»‡u nÃ o Ä‘Æ°á»£c táº£i. Vui lÃ²ng táº£i lÃªn hoáº·c náº¡p tÃ i liá»‡u trÆ°á»›c."

        # Kiá»ƒm tra cÃ¢u há»i
        if not question or len(question.strip()) < 2:
            return "Vui lÃ²ng Ä‘áº·t cÃ¢u há»i cá»¥ thá»ƒ hÆ¡n."

        # Gá»i chuá»—i RAG vá»›i xá»­ lÃ½ lá»—i chi tiáº¿t
        try:
            if callable(st.session_state.rag_chain):
                # Simple RAG chain (fallback)
                output = st.session_state.rag_chain(question)
            else:
                # LangChain RAG chain (khÃ´ng cÃ³ vÃ¬ Ä‘Ã£ bá» LLM)
                output = st.session_state.rag_chain(question)

        except Exception as chain_error:
            st.error(f"Lá»—i khi gá»i RAG chain: {str(chain_error)}")
            # Ultimate fallback: sá»­ dá»¥ng documents_text náº¿u cÃ³
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                return simple_text_retrieval(question, st.session_state.documents_text)
            else:
                return f"Xin lá»—i, gáº·p lá»—i khi xá»­ lÃ½ cÃ¢u há»i: {str(chain_error)}. Vui lÃ²ng thá»­ táº£i láº¡i tÃ i liá»‡u."

        # Xá»­ lÃ½ cÃ¡c Ä‘á»‹nh dáº¡ng Ä‘áº§u ra khÃ¡c nhau
        if isinstance(output, str):
            # Náº¿u Ä‘áº§u ra chá»©a "Answer:", trÃ­ch xuáº¥t pháº§n sau nÃ³
            if 'Answer:' in output:
                answer_parts = output.split('Answer:')
                if len(answer_parts) > 1:
                    answer = answer_parts[-1].strip()
                else:
                    answer = output.strip()
            elif 'Tráº£ lá»i:' in output:
                answer_parts = output.split('Tráº£ lá»i:')
                if len(answer_parts) > 1:
                    answer = answer_parts[-1].strip()
                else:
                    answer = output.strip()
            else:
                answer = output.strip()
        else:
            # Náº¿u Ä‘áº§u ra khÃ´ng pháº£i lÃ  chuá»—i, chuyá»ƒn Ä‘á»•i nÃ³
            answer = str(output).strip()

        # Äáº£m báº£o cÃ³ cÃ¢u tráº£ lá»i cÃ³ Ã½ nghÄ©a
        if not answer or len(answer) < 5:
            return "TÃ´i Ä‘Ã£ tÃ¬m tháº¥y má»™t sá»‘ thÃ´ng tin trong tÃ i liá»‡u, nhÆ°ng khÃ´ng thá»ƒ táº¡o ra cÃ¢u tráº£ lá»i rÃµ rÃ ng. Vui lÃ²ng thá»­ diá»…n Ä‘áº¡t láº¡i cÃ¢u há»i cá»§a báº¡n."

        # LÃ m sáº¡ch cÃ¢u tráº£ lá»i
        answer = answer.replace("Human:", "").replace("Assistant:", "").strip()

        return answer

    except Exception as e:
        st.error(f"Lá»—i khÃ´ng mong Ä‘á»£i: {str(e)}")
        # Thá»­ fallback cuá»‘i cÃ¹ng
        if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
            return simple_text_retrieval(question, st.session_state.documents_text)
        return "TÃ´i xin lá»—i, gáº·p lá»—i khÃ´ng mong Ä‘á»£i. Vui lÃ²ng thá»­ táº£i láº¡i tÃ i liá»‡u hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c."

def main():
    # Header vá»›i cá» Viá»‡t Nam
    st.markdown("""
    <div class="main-header">
        <div class="vietnam-flag"></div>
        <h1>ğŸ‡»ğŸ‡³ Trá»£ LÃ½ AI Tiáº¿ng Viá»‡t</h1>
        <p>Há»‡ thá»‘ng há»i Ä‘Ã¡p thÃ´ng minh vá»›i tÃ i liá»‡u PDF, Word, Excel báº±ng tiáº¿ng Viá»‡t</p>
        <p style="font-size: 14px; margin-top: 10px;">ğŸŒŸ Powered by Vietnamese AI Technology - No API Key Required! ğŸŒŸ</p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.header("âš™ï¸ Cáº¥u HÃ¬nh")

        if st.session_state.models_loaded:
            st.markdown('<span class="status-indicator status-ready"></span>**MÃ´ hÃ¬nh:** Sáºµn sÃ ng', unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-loading"></span>**MÃ´ hÃ¬nh:** Äang táº£i...', unsafe_allow_html=True)

        # Tráº¡ng thÃ¡i táº£i tÃ i liá»‡u
        if st.session_state.documents_loaded:
            st.markdown('<span class="status-indicator status-ready"></span>**TÃ i liá»‡u:** ÄÃ£ táº£i (FAISS)', unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-error"></span>**TÃ i liá»‡u:** ChÆ°a táº£i', unsafe_allow_html=True)

        st.divider()

        # Lá»±a chá»n nguá»“n tÃ i liá»‡u
        st.subheader("ğŸ“ Nguá»“n TÃ i Liá»‡u")

        pdf_source = st.radio(
            "Chá»n nguá»“n tÃ i liá»‡u:",
            ["Táº£i File LÃªn", "Táº£i ThÆ° Má»¥c (ZIP)", "GitHub Repository", "ÄÆ°á»ng Dáº«n ThÆ° Má»¥c"],
            key="pdf_source_radio"
        )

        if pdf_source == "Táº£i File LÃªn":
            st.session_state.pdf_source = "upload_files"

            st.markdown('<div class="upload-section">', unsafe_allow_html=True)
            st.markdown("**ğŸ“ Táº£i LÃªn Tá»«ng File**")
            uploaded_files = st.file_uploader(
                "Chá»n file Ä‘á»ƒ táº£i lÃªn:",
                type=['pdf', 'docx', 'xlsx', 'xls'],
                accept_multiple_files=True,
                help="Äá»‹nh dáº¡ng há»— trá»£: PDF, Word (.docx), Excel (.xlsx, .xls)"
            )
            st.markdown('</div>', unsafe_allow_html=True)

            if uploaded_files:
                st.markdown("**File ÄÃ£ Chá»n:**")
                for i, file in enumerate(uploaded_files):
                    file_size = len(file.getbuffer()) / (1024 * 1024)  # KÃ­ch thÆ°á»›c tÃ­nh báº±ng MB
                    st.markdown(f'<span class="file-counter">{i+1}. {file.name} ({file_size:.1f} MB)</span>', unsafe_allow_html=True)

                if st.button("ğŸ“¤ Xá»­ LÃ½ File ÄÃ£ Táº£i", type="primary"):
                    with st.spinner("Äang xá»­ lÃ½ file Ä‘Ã£ táº£i lÃªn..."):
                        all_documents = []
                        loaded_files = []

                        progress_bar = st.progress(0)

                        for i, file in enumerate(uploaded_files):
                            documents = extract_text_from_uploaded_file(file)
                            if documents:
                                all_documents.extend(documents)
                                loaded_files.append(file.name)
                                st.success(f"âœ… ÄÃ£ xá»­ lÃ½: {file.name}")
                            progress_bar.progress((i + 1) / len(uploaded_files))

                        progress_bar.empty()

                        if all_documents:
                            rag_chain, num_chunks = create_rag_chain(all_documents)
                            if rag_chain:
                                st.session_state.rag_chain = rag_chain
                                st.session_state.documents_loaded = True
                                st.success(f"âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng {len(loaded_files)} file!")
                                st.rerun()
                        else:
                            st.error("KhÃ´ng cÃ³ tÃ i liá»‡u nÃ o cÃ³ thá»ƒ Ä‘Æ°á»£c xá»­ lÃ½.")

        elif pdf_source == "Táº£i ThÆ° Má»¥c (ZIP)":
            st.session_state.pdf_source = "upload_zip"

            st.markdown('<div class="upload-section">', unsafe_allow_html=True)
            st.markdown("**ğŸ“ Táº£i ThÆ° Má»¥c DÆ°á»›i Dáº¡ng ZIP**")
            zip_file = st.file_uploader(
                "Chá»n file ZIP chá»©a tÃ i liá»‡u:",
                type=['zip'],
                help="Táº£i lÃªn file ZIP chá»©a file PDF, Word, hoáº·c Excel"
            )
            st.markdown('</div>', unsafe_allow_html=True)

            if zip_file:
                file_size = len(zip_file.getbuffer()) / (1024 * 1024)  # KÃ­ch thÆ°á»›c tÃ­nh báº±ng MB
                st.info(f"ğŸ“¦ File ZIP Ä‘Ã£ chá»n: {zip_file.name} ({file_size:.1f} MB)")

                if st.button("ğŸ“¤ Xá»­ LÃ½ File ZIP", type="primary"):
                    with st.spinner("Äang giáº£i nÃ©n vÃ  xá»­ lÃ½ file ZIP..."):
                        all_documents, loaded_files = process_zip_file(zip_file)

                        if all_documents:
                            rag_chain, num_chunks = create_rag_chain(all_documents)
                            if rag_chain:
                                st.session_state.rag_chain = rag_chain
                                st.session_state.documents_loaded = True
                                st.success(f"âœ… ÄÃ£ xá»­ lÃ½ thÃ nh cÃ´ng {len(loaded_files)} file tá»« ZIP!")
                                st.rerun()
                        else:
                            st.error("KhÃ´ng tÃ¬m tháº¥y tÃ i liá»‡u há»£p lá»‡ trong file ZIP.")

        elif pdf_source == "GitHub Repository":
            st.session_state.pdf_source = "github"
            github_url = st.text_input(
                "URL GitHub Repository:",
                value=st.session_state.github_repo_url,
                help="URL Ä‘áº¿n thÆ° má»¥c GitHub chá»©a file PDF"
            )
            st.session_state.github_repo_url = github_url

            if st.button("ğŸ“¥ Táº£i Tá»« GitHub", type="primary"):
                st.session_state.documents_loaded = False
                st.rerun()

        else:  # ÄÆ°á»ng Dáº«n ThÆ° Má»¥c
            st.session_state.pdf_source = "local"
            local_path = st.text_input(
                "ÄÆ°á»ng Dáº«n ThÆ° Má»¥c Cá»¥c Bá»™:",
                value=st.session_state.local_folder_path,
                help="ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c cá»¥c bá»™ chá»©a file PDF"
            )
            st.session_state.local_folder_path = local_path

            if st.button("ğŸ“‚ Táº£i Tá»« ThÆ° Má»¥c Cá»¥c Bá»™", type="primary"):
                st.session_state.documents_loaded = False
                st.rerun()

        st.divider()

        if st.button("ğŸ—‘ï¸ XÃ³a Lá»‹ch Sá»­ TrÃ² Chuyá»‡n"):
            st.session_state.chat_history = []
            st.session_state.processing_query = False
            st.rerun()

        if st.button("ğŸ—‘ï¸ XÃ³a Táº¥t Cáº£ TÃ i Liá»‡u"):
            st.session_state.documents_loaded = False
            st.session_state.rag_chain = None
            st.session_state.chat_history = []
            st.session_state.processing_query = False
            if hasattr(st.session_state, 'documents_text'):
                del st.session_state.documents_text
            st.rerun()

        # CÃ i Ä‘áº·t FAISS
        st.divider()
        st.subheader("ğŸ” CÃ i Äáº·t Há»‡ Thá»‘ng")
        st.info("ğŸš€ FAISS: ThÆ° viá»‡n tÃ¬m kiáº¿m tÆ°Æ¡ng tá»± nhanh")
        st.info("ğŸ” Keyword Search: TÃ¬m kiáº¿m tá»« khÃ³a thÃ´ng minh")
        st.info("ğŸŒ Hub Prompt: Sá»­ dá»¥ng rlm/rag-prompt template")

        st.divider()
        st.subheader("ğŸ‡»ğŸ‡³ MÃ´ HÃ¬nh Tiáº¿ng Viá»‡t")
        st.markdown("""
        <div style="background-color: #fff3cd; padding: 15px; border-radius: 8px; border-left: 4px solid #ffc107;">
            <div style="display: flex; align-items: center; margin-bottom: 10px;">
                <div class="vietnam-flag" style="margin-right: 15px;"></div>
                <strong>Vietnamese AI Technology</strong>
            </div>
            <p style="margin: 0; font-size: 14px;">
                âœ¨ Sá»­ dá»¥ng mÃ´ hÃ¬nh embedding 'bkai-foundation-models/vietnamese-bi-encoder'<br>
                ğŸš€ ÄÆ°á»£c tá»‘i Æ°u hÃ³a Ä‘áº·c biá»‡t cho ngÃ´n ngá»¯ tiáº¿ng Viá»‡t<br>
                ğŸ¯ Hiá»ƒu rÃµ ngá»¯ cáº£nh vÃ  tá»« ngá»¯ Viá»‡t Nam<br>
                ğŸ”‘ KhÃ´ng cáº§n API Key - Hoáº¡t Ä‘á»™ng offline!
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Debug section
        st.divider()
        st.subheader("ğŸ”§ Debug & Kiá»ƒm Tra")

        if st.button("ğŸ” Kiá»ƒm Tra Há»‡ Thá»‘ng"):
            st.write("**Tráº¡ng thÃ¡i Há»‡ Thá»‘ng:**")
            st.write(f"- Models loaded: {st.session_state.models_loaded}")
            st.write(f"- Embeddings: {'âœ…' if st.session_state.embeddings else 'âŒ'}")
            st.write(f"- Documents loaded: {st.session_state.documents_loaded}")
            st.write(f"- RAG chain: {'âœ…' if st.session_state.rag_chain else 'âŒ'}")
            st.write(f"- Mode: ğŸ” Keyword Search (No API required)")

            if hasattr(st.session_state, 'documents_text'):
                st.write(f"- Documents text length: {len(st.session_state.documents_text):,} characters")
            else:
                st.write("- Documents text: âŒ ChÆ°a cÃ³")

        if st.session_state.documents_loaded and st.button("ğŸ“„ Xem Máº«u Ná»™i Dung"):
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                preview = st.session_state.documents_text[:500] + "..." if len(st.session_state.documents_text) > 500 else st.session_state.documents_text
                st.text_area("Máº«u ná»™i dung tÃ i liá»‡u:", preview, height=200)

    # Táº£i mÃ´ hÃ¬nh náº¿u chÆ°a Ä‘Æ°á»£c táº£i
    if not st.session_state.models_loaded:
        with st.spinner("ğŸš€ Äang khá»Ÿi táº¡o embedding model tiáº¿ng Viá»‡t..."):
            try:
                st.session_state.embeddings = load_embeddings()
                st.success("âœ… ÄÃ£ táº£i embeddings model thÃ nh cÃ´ng")
            except Exception as e:
                st.error(f"âŒ Lá»—i khi táº£i embeddings: {str(e)}")
                st.warning("âš ï¸ Sáº½ hoáº¡t Ä‘á»™ng á»Ÿ cháº¿ Ä‘á»™ Ä‘Æ¡n giáº£n mÃ  khÃ´ng cÃ³ embeddings")
                st.session_state.embeddings = None

            st.session_state.models_loaded = True

        st.success("âœ… Há»‡ thá»‘ng Ä‘Ã£ sáºµn sÃ ng!")
        st.info("ğŸ” Äang hoáº¡t Ä‘á»™ng á»Ÿ cháº¿ Ä‘á»™ tÃ¬m kiáº¿m tá»« khÃ³a thÃ´ng minh")
        time.sleep(1)
        st.rerun()

    # Táº£i tÃ i liá»‡u náº¿u chÆ°a Ä‘Æ°á»£c táº£i vÃ  nguá»“n lÃ  github hoáº·c local
    if st.session_state.models_loaded and not st.session_state.documents_loaded and st.session_state.pdf_source in ["github", "local"]:
        with st.spinner("ğŸ“š Äang táº£i tÃ i liá»‡u vÃ o kho vector FAISS..."):
            #? rag_chain save into session state, and become available in every function e.g. process_user_query()
            if st.session_state.pdf_source == "github":
                st.session_state.rag_chain, num_chunks, loaded_files = load_pdfs_from_github(st.session_state.github_repo_url)
                print("\n---github---\n")

            else:
                st.session_state.rag_chain, num_chunks, loaded_files = load_pdfs_from_folder(st.session_state.local_folder_path)
                print("\n---load from folder---\n")

            if st.session_state.rag_chain:
                # st.session_state.rag_chain = rag_chain #? Lá»—i CHÃNH Ä‘áº·t sai biáº¿n. pháº£i ngÆ°á»£c láº¡i má»›i Ä‘Ãºng.
                st.session_state.documents_loaded = True

                st.markdown(f"""
                <div class="document-info">
                    <h4>ğŸ“„ ÄÃ£ táº£i thÃ nh cÃ´ng {len(loaded_files)} tÃ i liá»‡u PDF vÃ o FAISS:</h4>
                    <ul>
                        {"".join([f"<li>{file}</li>" for file in loaded_files])}
                    </ul>
                    <p><strong>Tá»•ng sá»‘ Ä‘oáº¡n:</strong> {num_chunks}</p>
                    <p><strong>Kho Vector:</strong> FAISS (TÃ¬m kiáº¿m tÆ°Æ¡ng tá»± nhanh)</p>
                    <p><strong>Cháº¿ Ä‘á»™:</strong> ğŸ” Keyword Search vá»›i RAG Prompt</p>
                    <p><strong>Template:</strong> rlm/rag-prompt tá»« LangChain Hub</p>
                </div>
                """, unsafe_allow_html=True)

                st.success("âœ… TÃ i liá»‡u Ä‘Ã£ sáºµn sÃ ng cho há»i Ä‘Ã¡p!")
                time.sleep(2)
                st.rerun()
            else:
                st.error("âŒ KhÃ´ng thá»ƒ táº£i tÃ i liá»‡u. Vui lÃ²ng kiá»ƒm tra cáº¥u hÃ¬nh cá»§a báº¡n.")

    # Giao diá»‡n trÃ² chuyá»‡n chÃ­nh
    if st.session_state.rag_chain:
        st.markdown("<div class='chat-container'>", unsafe_allow_html=True)

        for message in st.session_state.chat_history:
            display_chat_message(message["content"], message["is_user"])

        if st.session_state.processing_query:
            display_thinking_indicator()

        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("<div class='chat-input-container'>", unsafe_allow_html=True)

        with st.form(key="chat_form", clear_on_submit=True):
            col1, col2 = st.columns([4, 1])

            with col1:
                user_question = st.text_input(
                    "Nháº­p cÃ¢u há»i cá»§a báº¡n...",
                    placeholder="Há»i báº¥t cá»© Ä‘iá»u gÃ¬ vá» tÃ i liá»‡u...",
                    disabled=st.session_state.processing_query,
                    label_visibility="collapsed"
                )

            with col2:
                send_button = st.form_submit_button(
                    "ğŸ“¤ Gá»­i",
                    type="primary",
                    disabled=st.session_state.processing_query
                )

        st.markdown("</div>", unsafe_allow_html=True)

        # Xá»­ lÃ½ Ä‘áº§u vÃ o cá»§a ngÆ°á»i dÃ¹ng
        if send_button and user_question.strip() and not st.session_state.processing_query:
            st.session_state.processing_query = True

            st.session_state.chat_history.append({
                "content": user_question,
                "is_user": True
            })
            st.rerun()

        if st.session_state.processing_query and len(st.session_state.chat_history) > 0:
            if not st.session_state.chat_history[-1]["is_user"]:
                st.session_state.processing_query = False
            else:
                last_question = st.session_state.chat_history[-1]["content"]
                # answer = process_user_query(last_question)
                answer = st.session_state.rag_chain.invoke(last_question)

                st.session_state.chat_history.append({
                    "content": answer,
                    "is_user": False
                })

                st.session_state.processing_query = False

                st.rerun()
    else:
        # Tin nháº¯n chÃ o má»«ng
        st.markdown("""
        <div style='text-align: center; padding: 2rem;'>
            <h3>ğŸ‘‹ ChÃ o má»«ng Ä‘áº¿n vá»›i Trá»£ LÃ½ AI Tiáº¿ng Viá»‡t!</h3>
            <p><strong style="color: #28a745;">ğŸ”¥ KhÃ´ng cáº§n API Key - Hoáº¡t Ä‘á»™ng hoÃ n toÃ n offline!</strong></p>
            <br>
            <p>Há»‡ thá»‘ng nÃ y há»— trá»£ nhiá»u phÆ°Æ¡ng thá»©c nháº­p liá»‡u:</p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li><strong>ğŸ“ Táº£i File LÃªn:</strong>
                    <ul>
                        <li>TÃ i liá»‡u PDF (.pdf)</li>
                        <li>TÃ i liá»‡u Word (.docx)</li>
                        <li>Báº£ng tÃ­nh Excel (.xlsx, .xls)</li>
                    </ul>
                </li>
                <li><strong>ğŸ“ Táº£i ThÆ° Má»¥c (ZIP):</strong> Táº£i lÃªn file ZIP chá»©a nhiá»u tÃ i liá»‡u</li>
                <li><strong>ğŸ”— GitHub Repository:</strong> Táº£i file PDF tá»« kho GitHub</li>
                <li><strong>ğŸ“‚ ThÆ° Má»¥c Cá»¥c Bá»™:</strong> Táº£i file tá»« Ä‘Æ°á»ng dáº«n thÆ° má»¥c cá»¥c bá»™</li>
            </ul>
            <br>
            <p><strong>CÃ´ng Nghá»‡ Sá»­ Dá»¥ng:</strong></p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li><strong>ğŸ” Smart Keyword Search:</strong> TÃ¬m kiáº¿m tá»« khÃ³a thÃ´ng minh</li>
                <li><strong>ğŸŒ RAG Prompt:</strong> Sá»­ dá»¥ng template tá»« LangChain Hub</li>
                <li><strong>ğŸš€ FAISS Vector Store:</strong> TÃ¬m kiáº¿m tÆ°Æ¡ng tá»± nhanh</li>
                <li><strong>ğŸ‡»ğŸ‡³ Vietnamese Embeddings:</strong> Tá»‘i Æ°u cho tiáº¿ng Viá»‡t</li>
            </ul>
            <br>
            <p><strong>Äá»ƒ báº¯t Ä‘áº§u:</strong></p>
            <ol style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li>Chá»n nguá»“n tÃ i liá»‡u Æ°a thÃ­ch</li>
                <li>Táº£i lÃªn file hoáº·c cáº¥u hÃ¬nh repository/thÆ° má»¥c</li>
                <li>Xá»­ lÃ½ tÃ i liá»‡u cá»§a báº¡n</li>
                <li>Báº¯t Ä‘áº§u Ä‘áº·t cÃ¢u há»i!</li>
            </ol>
            <br>
            <p><strong>Repository Máº·c Äá»‹nh:</strong><br>
            <code>https://github.com/Jennifer1907/Time-Series-Team-Hub/tree/main/assets/pdf</code></p>
            <br>
            <p><strong>TÃ­nh NÄƒng Ná»•i Báº­t:</strong></p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li>âœ¨ Há»— trá»£ Ä‘a Ä‘á»‹nh dáº¡ng (PDF, Word, Excel)</li>
                <li>ğŸš€ Kho vector FAISS cho tÃ¬m kiáº¿m tÆ°Æ¡ng tá»± nhanh</li>
                <li>ğŸ‡»ğŸ‡³ Tá»‘i Æ°u cho tiáº¿ng Viá»‡t</li>
                <li>ğŸ”„ Nhiá»u phÆ°Æ¡ng thá»©c nháº­p liá»‡u</li>
                <li>ğŸ’¬ Giao diá»‡n trÃ² chuyá»‡n giá»‘ng ChatGPT</li>
                <li>ğŸ¯ Pháº£n há»“i nháº­n thá»©c ngá»¯ cáº£nh</li>
                <li>ğŸ”‘ KhÃ´ng cáº§n API Key - Hoáº¡t Ä‘á»™ng offline!</li>
                <li>ğŸŒ Sá»­ dá»¥ng RAG prompt template tá»« LangChain Hub</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()