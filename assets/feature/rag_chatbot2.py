from langchain_huggingface import HuggingFacePipeline
import streamlit as st
import os
import requests
import shutil
from pathlib import Path
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import Docx2txtLoader
from langchain_community.document_loaders import UnstructuredExcelLoader
from langchain_huggingface.embeddings import HuggingFaceEmbeddings
from langchain_experimental.text_splitter import SemanticChunker
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain import hub
from langchain.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
import time
import tempfile
import urllib.parse
import zipfile
from langchain_core.runnables import RunnableLambda
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer




st.set_page_config(
    page_title="Tr·ª£ L√Ω AI Ti·∫øng Vi·ªát",
    page_icon="ü§ñ",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
  .main-header{
    text-align: center;
    padding: 1rem 0;
    margin-bottom: 2rem;
    background: linear-gradient(90deg, #ff0000, #ffff00);
    border-radius: 10px;
    color: white;
  }
  .chat-container{
    max-width: 800px;
    margin: 0 auto;
    padding: 1rem;
    max-height: 500px;
    overflow-y: auto;
    border: 1px solid #e0e0e0;
    border-radius: 10px;
    margin-bottom: 20px;
    background-color: #fafafa;
  }
  .user-message{
    background-color: #000000;
    color: #ffffff;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-left: 20%;
    text-align: left;
    border: 1px solid #333333;
  }
  .assistant-message{
    background-color: #006400;
    color: #ffffff;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-right: 20%;
    text-align: left;
    border: 1px solid #228b22;
  }
  .chat-input-container {
    position: sticky;
    bottom: 0;
    background-color: white;
    padding: 1rem;
    border-top: 2px solid #e0e0e0;
    border-radius: 10px;
    margin-top: 20px;
  }
  .stTextInput > div > div > input {
    border-radius: 25px;
    border: 2px solid #e0e0e0;
    padding: 12px 20px;
    font-size: 16px;
  }
  .document-info {
    background-color: #f8f9fa;
    border-left: 4px solid #28a745;
    padding: 1rem;
    margin: 1rem 0;
    border-radius: 4px;
  }
  .status-indicator{
    display: inline-block;
    width: 12px;
    height: 12px;
    border-radius: 50%;
    margin-right: 8px;
  }
  .status-ready{
    background-color: #28a745;
  }
  .status-loading {
    background-color: #ffc107;
  }
  .status-error {
    background-color: #dc3545;
  }
  .thinking-indicator {
    background-color: #f5f5f5;
    border-radius: 18px;
    padding: 12px 16px;
    margin: 8px 0;
    margin-right: 20%;
    text-align: left;
    border: 1px solid #ddd;
    animation: pulse 1.5s ease-in-out infinite;
  }
  @keyframes pulse {
    0% { opacity: 0.6; }
    50% { opacity: 1; }
    100% { opacity: 0.6; }
  }
  .upload-section {
    background-color: #f8f9fa;
    border: 2px dashed #28a745;
    border-radius: 10px;
    padding: 20px;
    margin: 10px 0;
    text-align: center;
  }
  .file-counter {
    background-color: #e3f2fd;
    border-radius: 5px;
    padding: 5px 10px;
    margin: 5px;
    display: inline-block;
    font-size: 12px;
  }
  .vietnam-flag {
    background: #da020e;
    width: 40px;
    height: 28px;
    display: inline-block;
    margin-right: 10px;
    border-radius: 3px;
    position: relative;
  }
  .vietnam-flag::after {
    content: "‚≠ê";
    position: absolute;
    top: 50%;
    left: 50%;
    transform: translate(-50%, -50%);
    color: #ffcd00;
    font-size: 16px;
  }
</style>
""", unsafe_allow_html=True)

# Kh·ªüi t·∫°o session state
if 'chat_history' not in st.session_state:
    st.session_state.chat_history = []
if 'rag_chain' not in st.session_state:
    st.session_state.rag_chain = None
if 'documents_loaded' not in st.session_state:
    st.session_state.documents_loaded = False
if 'pdf_source' not in st.session_state:
    st.session_state.pdf_source = "github"
if 'github_repo_url' not in st.session_state:
    st.session_state.github_repo_url = "https://github.com/Jennifer1907/Time-Series-Team-Hub/tree/main/assets/pdf"
if 'local_folder_path' not in st.session_state:
    st.session_state.local_folder_path = "./knowledge_base"
if 'processing_query' not in st.session_state:
    st.session_state.processing_query = False
if 'query_input' not in st.session_state:
    st.session_state.query_input = ""

# Check if models downloaded or not
if 'models_loaded' not in st.session_state:
    st.session_state.models_loaded = False

# save downloaded embeding model
if 'embeddings' not in st.session_state:
    st.session_state.embeddings = None

# Save downloaded LLM
if 'llm' not in st.session_state:
    st.session_state.llm = None

# Import file processing function from process_file.py
from process_file import *
from load_llm import *

def format_docs(docs):
    if not docs:
        return "Kh√¥ng t√¨m th·∫•y t√†i li·ªáu li√™n quan."
    return "\n\n".join(doc.page_content for doc in docs)



def create_rag_chain(all_documents):
    """T·∫°o chu·ªói RAG t·ª´ t√†i li·ªáu"""
    if not all_documents:
        st.error("Kh√¥ng c√≥ t√†i li·ªáu n√†o ƒë·ªÉ x·ª≠ l√Ω")
        return None, 0

    try:
        st.info(f"üîÑ ƒêang x·ª≠ l√Ω {len(all_documents)} t√†i li·ªáu...")

        # Ki·ªÉm tra n·ªôi dung t√†i li·ªáu
        total_text = ""
        for doc in all_documents:
            if hasattr(doc, 'page_content'):
                total_text += doc.page_content + "\n"

        if len(total_text.strip()) < 50:
            st.error("N·ªôi dung t√†i li·ªáu qu√° ng·∫Øn ho·∫∑c kh√¥ng th·ªÉ ƒë·ªçc ƒë∆∞·ª£c")
            return None, 0

        st.success(f"‚úÖ ƒê√£ ƒë·ªçc {len(total_text):,} k√Ω t·ª± t·ª´ t√†i li·ªáu")

        # L∆∞u to√†n b·ªô text v√†o session state ƒë·ªÉ fallback
        st.session_state.documents_text = total_text

        # S·ª≠ d·ª•ng text splitter m·∫°nh m·∫Ω h∆°n n·∫øu SemanticChunker th·∫•t b·∫°i
        try:
            if st.session_state.embeddings:
                semantic_splitter = SemanticChunker(
                    embeddings=st.session_state.embeddings,
                    buffer_size=1,
                    breakpoint_threshold_type="percentile",
                    breakpoint_threshold_amount=95,
                    min_chunk_size=500,
                    add_start_index=True
                )
                docs = semantic_splitter.split_documents(all_documents)
                st.info(f"‚úÖ S·ª≠ d·ª•ng SemanticChunker: {len(docs)} chunks")
            else:
                raise Exception("No embeddings available")
        except Exception as e:
            st.warning(f"SemanticChunker th·∫•t b·∫°i: {str(e)}")
            st.info("üîÑ Chuy·ªÉn sang RecursiveCharacterTextSplitter...")
            # D·ª± ph√≤ng v·ªõi text splitter c∆° b·∫£n
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1000,
                chunk_overlap=200,
                length_function=len
            )
            docs = text_splitter.split_documents(all_documents)
            st.info(f"‚úÖ S·ª≠ d·ª•ng RecursiveCharacterTextSplitter: {len(docs)} chunks")

        if not docs:
            st.error("Kh√¥ng c√≥ ƒëo·∫°n t√†i li·ªáu n√†o ƒë∆∞·ª£c t·∫°o")
            # T·∫°o simple RAG chain v·ªõi to√†n b·ªô text
            def simple_rag_chain_text(question):
                return simple_text_retrieval(question, total_text)
            return simple_rag_chain_text, 1

        # Tri·ªÉn khai FAISS v·ªõi x·ª≠ l√Ω l·ªói (ch·ªâ khi c√≥ embeddings)
        if st.session_state.embeddings:
            try:
                vector_db = FAISS.from_documents(documents=docs, embedding=st.session_state.embeddings)
                retriever = vector_db.as_retriever(top_k=5)
                st.success(f"‚úÖ ƒê√£ t·∫°o FAISS vector database v·ªõi {len(docs)} chunks")
            except Exception as e:
                st.error(f"L·ªói khi t·∫°o FAISS vector database: {str(e)}")
                st.info("üîÑ Chuy·ªÉn sang ch·∫ø ƒë·ªô t√¨m ki·∫øm text ƒë∆°n gi·∫£n...")
                # Fallback to simple text search
                def simple_rag_chain_docs(question):
                    combined_text = "\n\n".join([doc.page_content for doc in docs])
                    return simple_text_retrieval(question, combined_text)
                return simple_rag_chain_docs, len(docs)
        else:
            st.info("üîç Kh√¥ng c√≥ embeddings, s·ª≠ d·ª•ng t√¨m ki·∫øm text ƒë∆°n gi·∫£n")
            def simple_rag_chain_docs(question):
                combined_text = "\n\n".join([doc.page_content for doc in docs])
                return simple_text_retrieval(question, combined_text)
            return simple_rag_chain_docs, len(docs)

        # S·ª≠ d·ª•ng t√¨m ki·∫øm t·ª´ kh√≥a th√¥ng minh v·ªõi hub prompt
        st.info("üîç S·ª≠ d·ª•ng t√¨m ki·∫øm t·ª´ kh√≥a th√¥ng minh v·ªõi RAG prompt")

        #? Code d∆∞ th·ª´a: prompt trong link rlm/rag-prompt v·ªõi prompt c·ª•c b·ªô gi·ªëng nhau
        # T·∫£i prompt t·ª´ hub
        # try:
        #     prompt = hub.pull("rlm/rag-prompt")
        #     st.success("‚úÖ ƒê√£ t·∫£i prompt template t·ª´ hub")
        # except Exception as e:
        # st.warning(f"Kh√¥ng th·ªÉ t·∫£i prompt t·ª´ hub: {str(e)}")
        st.info("üîÑ S·ª≠ d·ª•ng prompt template c·ª•c b·ªô...")

        # prompt = """S·ª≠ d·ª•ng nh·ªØng ƒëo·∫°n ng·ªØ c·∫£nh sau ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi ·ªü cu·ªëi.
        # N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, ch·ªâ c·∫ßn n√≥i r·∫±ng b·∫°n kh√¥ng bi·∫øt, ƒë·ª´ng c·ªë b·ªãa ra c√¢u tr·∫£ l·ªùi.
        # Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát.

        # Ng·ªØ c·∫£nh: {context}

        # C√¢u h·ªèi: {question}

        # Tr·∫£ l·ªùi:
        # """

        # prompt = """
        #     D·ª±a tr√™n c√°c m·ª•c ng·ªØ c·∫£nh sau, vui l√≤ng t·∫°o m·ªôt c√¢u h·ªèi tr·∫Øc nghi·ªám li√™n quan ƒë·∫øn '{query}' v·ªÅ m√£ Python. C√¢u h·ªèi ph·∫£i c√≥ m·ªôt ph·∫ßn th√¢n r√µ r√†ng v√† b·ªën l·ª±a ch·ªçn: m·ªôt c√¢u tr·∫£ l·ªùi ƒë√∫ng v√† ba c√¢u tr·∫£ l·ªùi sai nh∆∞ng c√≥ v·∫ª h·ª£p l√Ω. ƒê·∫£m b·∫£o r·∫±ng c√¢u tr·∫£ l·ªùi ƒë√∫ng ƒë∆∞·ª£c h·ªó tr·ª£ tr·ª±c ti·∫øp b·ªüi ng·ªØ c·∫£nh, v√† c√°c c√¢u tr·∫£ l·ªùi sai c√≥ li√™n quan ƒë·∫øn ch·ªß ƒë·ªÅ nh∆∞ng kh√¥ng ƒë√∫ng d·ª±a tr√™n ng·ªØ c·∫£nh.

        #     H∆∞·ªõng d·∫´n t·∫°o c√¢u h·ªèi:

        #         X√°c ƒë·ªãnh m·ªôt s·ª± th·∫≠t ho·∫∑c th√¥ng tin ch√≠nh t·ª´ ng·ªØ c·∫£nh li√™n quan ƒë·∫øn '{query}' c√≥ th·ªÉ ƒë∆∞·ª£c ki·ªÉm tra, ch·∫≥ng h·∫°n nh∆∞ m·ª•c ƒë√≠ch c·ªßa m·ªôt h√†m, gi√° tr·ªã c·ªßa m·ªôt bi·∫øn ho·∫∑c ƒë·∫ßu ra c·ªßa m·ªôt ƒëo·∫°n m√£.

        #         X√¢y d·ª±ng ph·∫ßn th√¢n c√¢u h·ªèi m·ªôt c√°ch r√µ r√†ng v√† c·ª• th·ªÉ.

        #         T·∫°o b·ªën l·ª±a ch·ªçn trong ƒë√≥ m·ªôt l·ª±a ch·ªçn l√† c√¢u tr·∫£ l·ªùi ƒë√∫ng, v√† ba l·ª±a ch·ªçn c√≤n l·∫°i l√† h·ª£p l√Ω nh∆∞ng kh√¥ng ƒë√∫ng.

        #         ƒê·∫£m b·∫£o r·∫±ng t·∫•t c·∫£ c√°c l·ª±a ch·ªçn c√≥ ƒë·ªô d√†i v√† ƒë·ªãnh d·∫°ng t∆∞∆°ng t·ª± nhau.

        #         Ng·∫´u nhi√™n h√≥a th·ª© t·ª± c√°c l·ª±a ch·ªçn ƒë·ªÉ c√¢u tr·∫£ l·ªùi ƒë√∫ng kh√¥ng ph·∫£i l√∫c n√†o c≈©ng ·ªü c√πng m·ªôt v·ªã tr√≠.

        #     Tr√¨nh b√†y c√¢u h·ªèi c·ªßa b·∫°n theo ƒë·ªãnh d·∫°ng n√†y:

        #     C√¢u h·ªèi: [ph·∫ßn th√¢n c√¢u h·ªèi]
        #     L·ª±a ch·ªçn:
        #     A)[l·ª±a ch·ªçn 1]
        #     B)[l·ª±a ch·ªçn 2]
        #     C)[l·ª±a ch·ªçn 3]
        #     D)[l·ª±a ch·ªçn 4]
        #     ƒê√°p √°n ƒë√∫ng: [ch·ªØ c√°i c·ªßa l·ª±a ch·ªçn ƒë√∫ng]

        #     V√≠ d·ª• v·ªÅ m·ªôt c√¢u h·ªèi tr·∫Øc nghi·ªám t·ªët:
        #     C√¢u h·ªèi: K·∫øt qu·∫£ c·ªßa print(2 + 3 * 4) trong Python s·∫Ω l√† g√¨?
        #     L·ª±a ch·ªçn:
        #     A) 20
        #     B) 14
        #     C) 24
        #     D) 10
        #     ƒê√°p √°n ƒë√∫ng: B

        #     Ng·ªØ c·∫£nh: {context}

        #     C√¢u h·ªèi: {question}

        #     Tr·∫£ l·ªùi:

        # """ #? d√πng {{ }} ƒë·ªÉ langchain kh√¥ng nh·∫≠n string b√™n trong {} l√† Bi·∫øn


        prompt = """
            B·∫°n l√† m·ªôt tr·ª£ l√Ω chuy√™n t·∫°o c√¢u h·ªèi tr·∫Øc nghi·ªám (MCQ).
            M·ªói c√¢u h·ªèi g·ªìm 1 c√¢u h·ªèi (question), 4 l·ª±a ch·ªçn, c√≤n ƒë∆∞·ª£c g·ªçi l√† choices (A, B, C, D), v√† ch·ªâ 1 ƒë√°p √°n ƒë√∫ng, ƒë∆∞·ª£c g·ªçi l√† correct.
            ƒê√°p √°n ƒë√∫ng ph·∫£i ƒë∆∞·ª£c ƒë√°nh d·∫•u r√µ.
            N·∫øu b·∫°n kh√¥ng bi·∫øt c√¢u tr·∫£ l·ªùi, ch·ªâ c·∫ßn n√≥i r·∫±ng b·∫°n kh√¥ng bi·∫øt.

            Tr·∫£ v·ªÅ output d∆∞·ªõi d·∫°ng JSON duy nh·∫•t v·ªõi ƒë√∫ng b·ªën kh√≥a. Ch·ªâ xu·∫•t ra ƒë·ªëi t∆∞·ª£ng JSON, kh√¥ng th√™m b·∫•t k·ª≥ n·ªôi dung n√†o kh√°c.

            V√≠ d·ª• v·ªÅ ƒë·∫ßu ra JSON:
            {{
                "question": "...",
                "choices": {{
                    "A": "...",
                    "B": "...",
                    "C": "...",
                    "D": "..."
                }},
                "correct": "...",
                "explanation": "..."
            }}

            Context: {context}
            Question: {question}


            H√£y t·∫°o 1 c√¢u h·ªèi tr·∫Øc nghi·ªám bao g·ªìm 4 l·ª±a ch·ªçn a) b) c) d) 
        """

        prompt_template = PromptTemplate(
            template=prompt,
            input_variables=["context", "question"]
        )


        rag_chain = (
            {
                "context": retriever | format_docs,
                "question": RunnablePassthrough()
            }
            | prompt_template
            | st.session_state.llm
            | StrOutputParser()
        )
        st.write(f"___[DEBUG]__\n")

        # T·∫°o simple RAG chain s·ª≠ d·ª•ng keyword search v·ªõi prompt
        # def smart_rag_chain_with_prompt(question):
        #     try:
        #         # T√¨m t√†i li·ªáu li√™n quan b·∫±ng retriever
        #         relevant_docs = retriever.get_relevant_documents(question)
        #         context = format_docs(relevant_docs)

        #         # S·ª≠ d·ª•ng simple text generation ƒë·ªÉ tr·∫£ l·ªùi
        #         context = simple_text_retrieval(question, context)

        #         rag_chain = (
        #             {
        #                 "context": RunnableLambda(lambda _: context),
        #                 "question": RunnablePassthrough()
        #             }
        #             | prompt
        #             | st.session_state.llm
        #             | StrOutputParser()
        #         )

        #         return rag_chain

        #     except Exception as e:
        #         st.warning(f"L·ªói retriever: {str(e)}, s·ª≠ d·ª•ng to√†n b·ªô text")
        #         context = simple_text_retrieval(question, total_text)

        #         rag_chain = (
        #             {
        #                 "context": RunnableLambda(lambda _: context),
        #                 "question": RunnablePassthrough()
        #             }
        #             | prompt
        #             | st.session_state.llm
        #             | StrOutputParser()
        #         )
        #         st.write(f"[DEBUG] L·ªói retriever fallback: {str(e)}")

        #         return rag_chain, len(docs)

        return rag_chain, len(docs) # basically return rag_chain, len(docs)

    except Exception as e:
        st.error(f"L·ªói nghi√™m tr·ªçng khi t·∫°o chu·ªói RAG: {str(e)}")
        st.info("üîÑ T·∫°o fallback RAG chain...")
        # Ultimate fallback
        def emergency_rag_chain(question):
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                return simple_text_retrieval(question, st.session_state.documents_text)
            else:
                return "Xin l·ªói, kh√¥ng th·ªÉ truy c·∫≠p n·ªôi dung t√†i li·ªáu. Vui l√≤ng t·∫£i l·∫°i t√†i li·ªáu."
        return emergency_rag_chain, 1

def load_pdfs_from_github(repo_url):
    """T·∫£i file PDF t·ª´ GitHub repository"""
    pdf_files = get_github_pdf_files(repo_url)

    if not pdf_files:
        st.warning("Kh√¥ng t√¨m th·∫•y file PDF n√†o trong GitHub repository")
        return None, 0, []

    temp_dir = tempfile.mkdtemp()
    all_documents = []
    loaded_files = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, pdf_file in enumerate(pdf_files):
        try:
            status_text.text(f"ƒêang t·∫£i v√† x·ª≠ l√Ω: {pdf_file['name']}")
            local_path = download_pdf_from_url(pdf_file['download_url'], pdf_file['name'], temp_dir)

            if local_path:
                loader = PyPDFLoader(local_path)
                documents = loader.load()
                all_documents.extend(documents)
                loaded_files.append(pdf_file['name'])

                st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {pdf_file['name']} ({len(documents)} trang)")
            progress_bar.progress((i + 1) / len(pdf_files))
        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω {pdf_file['name']}: {str(e)}")

    progress_bar.empty()
    status_text.empty()

    # D·ªçn d·∫πp th∆∞ m·ª•c t·∫°m th·ªùi
    shutil.rmtree(temp_dir)

    if not all_documents:
        return None, 0, loaded_files

    rag_chain, num_chunks = create_rag_chain(all_documents)
    return rag_chain, num_chunks, loaded_files

def load_pdfs_from_folder(folder_path):
    """T·∫£i t·∫•t c·∫£ file PDF t·ª´ th∆∞ m·ª•c ƒë∆∞·ª£c ch·ªâ ƒë·ªãnh"""
    cleaned_path = folder_path.strip().strip('"').strip("'")
    folder = Path(cleaned_path)

    if not folder.exists():
        st.error(f"‚ùå Th∆∞ m·ª•c kh√¥ng t·ªìn t·∫°i: `{cleaned_path}`")
        return None, 0, []

    pdf_files = list(folder.glob("*.pdf"))
    if not pdf_files:
        st.warning(f"Kh√¥ng t√¨m th·∫•y file PDF n√†o trong th∆∞ m·ª•c: {cleaned_path}")
        return None, 0, []

    all_documents = []
    loaded_files = []

    progress_bar = st.progress(0)
    status_text = st.empty()

    for i, pdf_file in enumerate(pdf_files):
        try:
            status_text.text(f"ƒêang x·ª≠ l√Ω: {pdf_file.name}")
            loader = PyPDFLoader(str(pdf_file))
            documents = loader.load()
            all_documents.extend(documents)
            loaded_files.append(pdf_file.name)
            progress_bar.progress((i + 1) / len(pdf_files))
            st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {pdf_file.name} ({len(documents)} trang)")

        except Exception as e:
            st.error(f"‚ùå L·ªói khi x·ª≠ l√Ω {pdf_file.name}: {str(e)}")

    progress_bar.empty()
    status_text.empty()

    if not all_documents:
        return None, 0, loaded_files

    rag_chain, num_chunks = create_rag_chain(all_documents)
    return rag_chain, num_chunks, loaded_files

def display_chat_message(message, is_user=True):
    """Hi·ªÉn th·ªã tin nh·∫Øn tr√≤ chuy·ªán"""
    if is_user:
        st.markdown(f"""
        <div class="user-message">
            <strong style="color: #ffffff;">B·∫°n:</strong> <span style="color: #ffffff;">{message}</span>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown(f"""
        <div class="assistant-message">
            <strong style="color: #ffffff;">Tr·ª£ L√Ω AI:</strong> <span style="color: #ffffff;">{message}</span>
        </div>
        """, unsafe_allow_html=True)

def display_thinking_indicator():
    """Hi·ªÉn th·ªã ch·ªâ b√°o ƒëang suy nghƒ©"""
    st.markdown(f"""
    <div class="thinking-indicator">
        <strong>Tr·ª£ L√Ω AI:</strong> ü§î ƒêang suy nghƒ©...
    </div>
    """, unsafe_allow_html=True)

#? rag_chain.invoke typeof function
def process_user_query(question):
    """X·ª≠ l√Ω c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng"""
    try:
        if not st.session_state.rag_chain:
            return "Xin l·ªói, ch∆∞a c√≥ t√†i li·ªáu n√†o ƒë∆∞·ª£c t·∫£i. Vui l√≤ng t·∫£i l√™n ho·∫∑c n·∫°p t√†i li·ªáu tr∆∞·ªõc."

        # Ki·ªÉm tra c√¢u h·ªèi
        if not question or len(question.strip()) < 2:
            return "Vui l√≤ng ƒë·∫∑t c√¢u h·ªèi c·ª• th·ªÉ h∆°n."

        # G·ªçi chu·ªói RAG v·ªõi x·ª≠ l√Ω l·ªói chi ti·∫øt
        try:
            if callable(st.session_state.rag_chain):
                # Simple RAG chain (fallback)
                output = st.session_state.rag_chain(question)
            else:
                # LangChain RAG chain (kh√¥ng c√≥ v√¨ ƒë√£ b·ªè LLM)
                output = st.session_state.rag_chain(question)

        except Exception as chain_error:
            st.error(f"L·ªói khi g·ªçi RAG chain: {str(chain_error)}")
            # Ultimate fallback: s·ª≠ d·ª•ng documents_text n·∫øu c√≥
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                return simple_text_retrieval(question, st.session_state.documents_text)
            else:
                return f"Xin l·ªói, g·∫∑p l·ªói khi x·ª≠ l√Ω c√¢u h·ªèi: {str(chain_error)}. Vui l√≤ng th·ª≠ t·∫£i l·∫°i t√†i li·ªáu."

        # X·ª≠ l√Ω c√°c ƒë·ªãnh d·∫°ng ƒë·∫ßu ra kh√°c nhau
        if isinstance(output, str):
            # N·∫øu ƒë·∫ßu ra ch·ª©a "Answer:", tr√≠ch xu·∫•t ph·∫ßn sau n√≥
            if 'Answer:' in output:
                answer_parts = output.split('Answer:')
                if len(answer_parts) > 1:
                    answer = answer_parts[-1].strip()
                else:
                    answer = output.strip()
            elif 'Tr·∫£ l·ªùi:' in output:
                answer_parts = output.split('Tr·∫£ l·ªùi:')
                if len(answer_parts) > 1:
                    answer = answer_parts[-1].strip()
                else:
                    answer = output.strip()
            else:
                answer = output.strip()
        else:
            # N·∫øu ƒë·∫ßu ra kh√¥ng ph·∫£i l√† chu·ªói, chuy·ªÉn ƒë·ªïi n√≥
            answer = str(output).strip()

        # ƒê·∫£m b·∫£o c√≥ c√¢u tr·∫£ l·ªùi c√≥ √Ω nghƒ©a
        if not answer or len(answer) < 5:
            return "T√¥i ƒë√£ t√¨m th·∫•y m·ªôt s·ªë th√¥ng tin trong t√†i li·ªáu, nh∆∞ng kh√¥ng th·ªÉ t·∫°o ra c√¢u tr·∫£ l·ªùi r√µ r√†ng. Vui l√≤ng th·ª≠ di·ªÖn ƒë·∫°t l·∫°i c√¢u h·ªèi c·ªßa b·∫°n."

        # L√†m s·∫°ch c√¢u tr·∫£ l·ªùi
        answer = answer.replace("Human:", "").replace("Assistant:", "").strip()

        return answer

    except Exception as e:
        st.error(f"L·ªói kh√¥ng mong ƒë·ª£i: {str(e)}")
        # Th·ª≠ fallback cu·ªëi c√πng
        if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
            return simple_text_retrieval(question, st.session_state.documents_text)
        return "T√¥i xin l·ªói, g·∫∑p l·ªói kh√¥ng mong ƒë·ª£i. Vui l√≤ng th·ª≠ t·∫£i l·∫°i t√†i li·ªáu ho·∫∑c ƒë·∫∑t c√¢u h·ªèi kh√°c."

def main():
    # Header v·ªõi c·ªù Vi·ªát Nam
    st.markdown("""
    <div class="main-header">
        <div class="vietnam-flag"></div>
        <h1>üáªüá≥ Tr·ª£ L√Ω AI Ti·∫øng Vi·ªát</h1>
        <p>H·ªá th·ªëng h·ªèi ƒë√°p th√¥ng minh v·ªõi t√†i li·ªáu PDF, Word, Excel b·∫±ng ti·∫øng Vi·ªát</p>
        <p style="font-size: 14px; margin-top: 10px;">üåü Powered by Vietnamese AI Technology - No API Key Required! üåü</p>
    </div>
    """, unsafe_allow_html=True)

    with st.sidebar:
        st.header("‚öôÔ∏è C·∫•u H√¨nh")

        if st.session_state.models_loaded:
            st.markdown('<span class="status-indicator status-ready"></span>**M√¥ h√¨nh:** S·∫µn s√†ng', unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-loading"></span>**M√¥ h√¨nh:** ƒêang t·∫£i...', unsafe_allow_html=True)

        # Tr·∫°ng th√°i t·∫£i t√†i li·ªáu
        if st.session_state.documents_loaded:
            st.markdown('<span class="status-indicator status-ready"></span>**T√†i li·ªáu:** ƒê√£ t·∫£i (FAISS)', unsafe_allow_html=True)
        else:
            st.markdown('<span class="status-indicator status-error"></span>**T√†i li·ªáu:** Ch∆∞a t·∫£i', unsafe_allow_html=True)

        st.divider()

        # L·ª±a ch·ªçn ngu·ªìn t√†i li·ªáu
        st.subheader("üìÅ Ngu·ªìn T√†i Li·ªáu")

        pdf_source = st.radio(
            "Ch·ªçn ngu·ªìn t√†i li·ªáu:",
            ["T·∫£i File L√™n", "T·∫£i Th∆∞ M·ª•c (ZIP)", "GitHub Repository", "ƒê∆∞·ªùng D·∫´n Th∆∞ M·ª•c"],
            key="pdf_source_radio"
        )

        if pdf_source == "T·∫£i File L√™n":
            st.session_state.pdf_source = "upload_files"

            st.markdown('<div class="upload-section">', unsafe_allow_html=True)
            st.markdown("**üìé T·∫£i L√™n T·ª´ng File**")
            uploaded_files = st.file_uploader(
                "Ch·ªçn file ƒë·ªÉ t·∫£i l√™n:",
                type=['pdf', 'docx', 'xlsx', 'xls'],
                accept_multiple_files=True,
                help="ƒê·ªãnh d·∫°ng h·ªó tr·ª£: PDF, Word (.docx), Excel (.xlsx, .xls)"
            )
            st.markdown('</div>', unsafe_allow_html=True)

            if uploaded_files:
                st.markdown("**File ƒê√£ Ch·ªçn:**")
                for i, file in enumerate(uploaded_files):
                    file_size = len(file.getbuffer()) / (1024 * 1024)  # K√≠ch th∆∞·ªõc t√≠nh b·∫±ng MB
                    st.markdown(f'<span class="file-counter">{i+1}. {file.name} ({file_size:.1f} MB)</span>', unsafe_allow_html=True)

                if st.button("üì§ X·ª≠ L√Ω File ƒê√£ T·∫£i", type="primary"):
                    with st.spinner("ƒêang x·ª≠ l√Ω file ƒë√£ t·∫£i l√™n..."):
                        all_documents = []
                        loaded_files = []

                        progress_bar = st.progress(0)

                        for i, file in enumerate(uploaded_files):
                            documents = extract_text_from_uploaded_file(file)
                            if documents:
                                all_documents.extend(documents)
                                loaded_files.append(file.name)
                                st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω: {file.name}")
                            progress_bar.progress((i + 1) / len(uploaded_files))

                        progress_bar.empty()

                        if all_documents:
                            rag_chain, num_chunks = create_rag_chain(all_documents)
                            if rag_chain:
                                st.session_state.rag_chain = rag_chain
                                st.session_state.documents_loaded = True
                                st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {len(loaded_files)} file!")
                                st.rerun()
                        else:
                            st.error("Kh√¥ng c√≥ t√†i li·ªáu n√†o c√≥ th·ªÉ ƒë∆∞·ª£c x·ª≠ l√Ω.")

        elif pdf_source == "T·∫£i Th∆∞ M·ª•c (ZIP)":
            st.session_state.pdf_source = "upload_zip"

            st.markdown('<div class="upload-section">', unsafe_allow_html=True)
            st.markdown("**üìÅ T·∫£i Th∆∞ M·ª•c D∆∞·ªõi D·∫°ng ZIP**")
            zip_file = st.file_uploader(
                "Ch·ªçn file ZIP ch·ª©a t√†i li·ªáu:",
                type=['zip'],
                help="T·∫£i l√™n file ZIP ch·ª©a file PDF, Word, ho·∫∑c Excel"
            )
            st.markdown('</div>', unsafe_allow_html=True)

            if zip_file:
                file_size = len(zip_file.getbuffer()) / (1024 * 1024)  # K√≠ch th∆∞·ªõc t√≠nh b·∫±ng MB
                st.info(f"üì¶ File ZIP ƒë√£ ch·ªçn: {zip_file.name} ({file_size:.1f} MB)")

                if st.button("üì§ X·ª≠ L√Ω File ZIP", type="primary"):
                    with st.spinner("ƒêang gi·∫£i n√©n v√† x·ª≠ l√Ω file ZIP..."):
                        all_documents, loaded_files = process_zip_file(zip_file)

                        if all_documents:
                            rag_chain, num_chunks = create_rag_chain(all_documents)
                            if rag_chain:
                                st.session_state.rag_chain = rag_chain
                                st.session_state.documents_loaded = True
                                st.success(f"‚úÖ ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng {len(loaded_files)} file t·ª´ ZIP!")
                                st.rerun()
                        else:
                            st.error("Kh√¥ng t√¨m th·∫•y t√†i li·ªáu h·ª£p l·ªá trong file ZIP.")

        elif pdf_source == "GitHub Repository":
            st.session_state.pdf_source = "github"
            github_url = st.text_input(
                "URL GitHub Repository:",
                value=st.session_state.github_repo_url,
                help="URL ƒë·∫øn th∆∞ m·ª•c GitHub ch·ª©a file PDF"
            )
            st.session_state.github_repo_url = github_url

            if st.button("üì• T·∫£i T·ª´ GitHub", type="primary"):
                st.session_state.documents_loaded = False
                st.rerun()

        else:  # ƒê∆∞·ªùng D·∫´n Th∆∞ M·ª•c
            st.session_state.pdf_source = "local"
            local_path = st.text_input(
                "ƒê∆∞·ªùng D·∫´n Th∆∞ M·ª•c C·ª•c B·ªô:",
                value=st.session_state.local_folder_path,
                help="ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c c·ª•c b·ªô ch·ª©a file PDF"
            )
            st.session_state.local_folder_path = local_path

            if st.button("üìÇ T·∫£i T·ª´ Th∆∞ M·ª•c C·ª•c B·ªô", type="primary"):
                st.session_state.documents_loaded = False
                st.rerun()

        st.divider()

        if st.button("üóëÔ∏è X√≥a L·ªãch S·ª≠ Tr√≤ Chuy·ªán"):
            st.session_state.chat_history = []
            st.session_state.processing_query = False
            st.rerun()

        if st.button("üóëÔ∏è X√≥a T·∫•t C·∫£ T√†i Li·ªáu"):
            st.session_state.documents_loaded = False
            st.session_state.rag_chain = None
            st.session_state.chat_history = []
            st.session_state.processing_query = False
            if hasattr(st.session_state, 'documents_text'):
                del st.session_state.documents_text
            st.rerun()

        # C√†i ƒë·∫∑t FAISS
        st.divider()
        st.subheader("üîç C√†i ƒê·∫∑t H·ªá Th·ªëng")
        st.info("üöÄ FAISS: Th∆∞ vi·ªán t√¨m ki·∫øm t∆∞∆°ng t·ª± nhanh")
        st.info("üîç Keyword Search: T√¨m ki·∫øm t·ª´ kh√≥a th√¥ng minh")
        st.info("üåê Hub Prompt: S·ª≠ d·ª•ng rlm/rag-prompt template")

        st.divider()
        st.subheader("üáªüá≥ M√¥ H√¨nh Ti·∫øng Vi·ªát")
        st.markdown("""
        <div style="background-color: #fff3cd; padding: 15px; border-radius: 8px; border-left: 4px solid #ffc107;">
            <div style="display: flex; align-items: center; margin-bottom: 10px;">
                <div class="vietnam-flag" style="margin-right: 15px;"></div>
                <strong>Vietnamese AI Technology</strong>
            </div>
            <p style="margin: 0; font-size: 14px;">
                ‚ú® S·ª≠ d·ª•ng m√¥ h√¨nh embedding 'bkai-foundation-models/vietnamese-bi-encoder'<br>
                üöÄ ƒê∆∞·ª£c t·ªëi ∆∞u h√≥a ƒë·∫∑c bi·ªát cho ng√¥n ng·ªØ ti·∫øng Vi·ªát<br>
                üéØ Hi·ªÉu r√µ ng·ªØ c·∫£nh v√† t·ª´ ng·ªØ Vi·ªát Nam<br>
                üîë Kh√¥ng c·∫ßn API Key - Ho·∫°t ƒë·ªông offline!
            </p>
        </div>
        """, unsafe_allow_html=True)

        # Debug section
        st.divider()
        st.subheader("üîß Debug & Ki·ªÉm Tra")

        if st.button("üîç Ki·ªÉm Tra H·ªá Th·ªëng"):
            st.write("**Tr·∫°ng th√°i H·ªá Th·ªëng:**")
            st.write(f"- Models loaded: {st.session_state.models_loaded}")
            st.write(f"- Embeddings: {'‚úÖ' if st.session_state.embeddings else '‚ùå'}")
            st.write(f"- Documents loaded: {st.session_state.documents_loaded}")
            st.write(f"- RAG chain: {'‚úÖ' if st.session_state.rag_chain else '‚ùå'}")
            st.write(f"- Mode: üîç Keyword Search (No API required)")

            if hasattr(st.session_state, 'documents_text'):
                st.write(f"- Documents text length: {len(st.session_state.documents_text):,} characters")
            else:
                st.write("- Documents text: ‚ùå Ch∆∞a c√≥")

        if st.session_state.documents_loaded and st.button("üìÑ Xem M·∫´u N·ªôi Dung"):
            if hasattr(st.session_state, 'documents_text') and st.session_state.documents_text:
                preview = st.session_state.documents_text[:500] + "..." if len(st.session_state.documents_text) > 500 else st.session_state.documents_text
                st.text_area("M·∫´u n·ªôi dung t√†i li·ªáu:", preview, height=200)

    # T·∫£i m√¥ h√¨nh n·∫øu ch∆∞a ƒë∆∞·ª£c t·∫£i
    if not st.session_state.models_loaded:
        with st.spinner("üöÄ ƒêang kh·ªüi t·∫°o embedding model ti·∫øng Vi·ªát..."):
            try:
                st.session_state.embeddings = load_embeddings()
                st.success("‚úÖ ƒê√£ t·∫£i embeddings model th√†nh c√¥ng")
            except Exception as e:
                st.error(f"‚ùå L·ªói khi t·∫£i embeddings: {str(e)}")
                st.warning("‚ö†Ô∏è S·∫Ω ho·∫°t ƒë·ªông ·ªü ch·∫ø ƒë·ªô ƒë∆°n gi·∫£n m√† kh√¥ng c√≥ embeddings")
                st.session_state.embeddings = None

            st.session_state.models_loaded = True

        st.success("‚úÖ H·ªá th·ªëng ƒë√£ s·∫µn s√†ng!")
        st.info("üîç ƒêang ho·∫°t ƒë·ªông ·ªü ch·∫ø ƒë·ªô t√¨m ki·∫øm t·ª´ kh√≥a th√¥ng minh")
        time.sleep(1)
        st.rerun()

    # T·∫£i t√†i li·ªáu n·∫øu ch∆∞a ƒë∆∞·ª£c t·∫£i v√† ngu·ªìn l√† github ho·∫∑c local
    if st.session_state.models_loaded and not st.session_state.documents_loaded and st.session_state.pdf_source in ["github", "local"]:
        with st.spinner("üìö ƒêang t·∫£i t√†i li·ªáu v√†o kho vector FAISS..."):
            #? rag_chain save into session state, and become available in every function e.g. process_user_query()
            if st.session_state.pdf_source == "github":
                st.session_state.rag_chain, num_chunks, loaded_files = load_pdfs_from_github(st.session_state.github_repo_url)
                print("\n---github---\n")

            else:
                st.session_state.rag_chain, num_chunks, loaded_files = load_pdfs_from_folder(st.session_state.local_folder_path)
                print("\n---load from folder---\n")

            if st.session_state.rag_chain:
                # st.session_state.rag_chain = rag_chain #? L·ªói CH√çNH ƒë·∫∑t sai bi·∫øn. ph·∫£i ng∆∞·ª£c l·∫°i m·ªõi ƒë√∫ng.
                st.session_state.documents_loaded = True

                st.markdown(f"""
                <div class="document-info">
                    <h4>üìÑ ƒê√£ t·∫£i th√†nh c√¥ng {len(loaded_files)} t√†i li·ªáu PDF v√†o FAISS:</h4>
                    <ul>
                        {"".join([f"<li>{file}</li>" for file in loaded_files])}
                    </ul>
                    <p><strong>T·ªïng s·ªë ƒëo·∫°n:</strong> {num_chunks}</p>
                    <p><strong>Kho Vector:</strong> FAISS (T√¨m ki·∫øm t∆∞∆°ng t·ª± nhanh)</p>
                    <p><strong>Ch·∫ø ƒë·ªô:</strong> üîç Keyword Search v·ªõi RAG Prompt</p>
                    <p><strong>Template:</strong> rlm/rag-prompt t·ª´ LangChain Hub</p>
                </div>
                """, unsafe_allow_html=True)

                st.success("‚úÖ T√†i li·ªáu ƒë√£ s·∫µn s√†ng cho h·ªèi ƒë√°p!")
                time.sleep(2)
                st.rerun()
            else:
                st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i t√†i li·ªáu. Vui l√≤ng ki·ªÉm tra c·∫•u h√¨nh c·ªßa b·∫°n.")

    # Giao di·ªán tr√≤ chuy·ªán ch√≠nh
    if st.session_state.rag_chain:
        st.markdown("<div class='chat-container'>", unsafe_allow_html=True)

        for message in st.session_state.chat_history:
            display_chat_message(message["content"], message["is_user"])

        if st.session_state.processing_query:
            display_thinking_indicator()

        st.markdown("</div>", unsafe_allow_html=True)

        st.markdown("<div class='chat-input-container'>", unsafe_allow_html=True)

        with st.form(key="chat_form", clear_on_submit=True):
            col1, col2 = st.columns([4, 1])

            with col1:
                user_question = st.text_input(
                    "Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n...",
                    placeholder="H·ªèi b·∫•t c·ª© ƒëi·ªÅu g√¨ v·ªÅ t√†i li·ªáu...",
                    disabled=st.session_state.processing_query,
                    label_visibility="collapsed"
                )

            with col2:
                send_button = st.form_submit_button(
                    "üì§ G·ª≠i",
                    type="primary",
                    disabled=st.session_state.processing_query
                )

        st.markdown("</div>", unsafe_allow_html=True)

        # X·ª≠ l√Ω ƒë·∫ßu v√†o c·ªßa ng∆∞·ªùi d√πng
        if send_button and user_question.strip() and not st.session_state.processing_query:
            st.session_state.processing_query = True

            st.session_state.chat_history.append({
                "content": user_question,
                "is_user": True
            })
            st.rerun()

        if st.session_state.processing_query and len(st.session_state.chat_history) > 0:
            if not st.session_state.chat_history[-1]["is_user"]:
                st.session_state.processing_query = False
            else:
                last_question = st.session_state.chat_history[-1]["content"]
                # answer = process_user_query(last_question)
                answer = st.session_state.rag_chain.invoke(last_question)

                st.session_state.chat_history.append({
                    "content": answer,
                    "is_user": False
                })

                st.session_state.processing_query = False

                st.rerun()
    else:
        # Tin nh·∫Øn ch√†o m·ª´ng
        st.markdown("""
        <div style='text-align: center; padding: 2rem;'>
            <h3>üëã Ch√†o m·ª´ng ƒë·∫øn v·ªõi Tr·ª£ L√Ω AI Ti·∫øng Vi·ªát!</h3>
            <p><strong style="color: #28a745;">üî• Kh√¥ng c·∫ßn API Key - Ho·∫°t ƒë·ªông ho√†n to√†n offline!</strong></p>
            <br>
            <p>H·ªá th·ªëng n√†y h·ªó tr·ª£ nhi·ªÅu ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu:</p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li><strong>üìé T·∫£i File L√™n:</strong>
                    <ul>
                        <li>T√†i li·ªáu PDF (.pdf)</li>
                        <li>T√†i li·ªáu Word (.docx)</li>
                        <li>B·∫£ng t√≠nh Excel (.xlsx, .xls)</li>
                    </ul>
                </li>
                <li><strong>üìÅ T·∫£i Th∆∞ M·ª•c (ZIP):</strong> T·∫£i l√™n file ZIP ch·ª©a nhi·ªÅu t√†i li·ªáu</li>
                <li><strong>üîó GitHub Repository:</strong> T·∫£i file PDF t·ª´ kho GitHub</li>
                <li><strong>üìÇ Th∆∞ M·ª•c C·ª•c B·ªô:</strong> T·∫£i file t·ª´ ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c c·ª•c b·ªô</li>
            </ul>
            <br>
            <p><strong>C√¥ng Ngh·ªá S·ª≠ D·ª•ng:</strong></p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li><strong>üîç Smart Keyword Search:</strong> T√¨m ki·∫øm t·ª´ kh√≥a th√¥ng minh</li>
                <li><strong>üåê RAG Prompt:</strong> S·ª≠ d·ª•ng template t·ª´ LangChain Hub</li>
                <li><strong>üöÄ FAISS Vector Store:</strong> T√¨m ki·∫øm t∆∞∆°ng t·ª± nhanh</li>
                <li><strong>üáªüá≥ Vietnamese Embeddings:</strong> T·ªëi ∆∞u cho ti·∫øng Vi·ªát</li>
            </ul>
            <br>
            <p><strong>ƒê·ªÉ b·∫Øt ƒë·∫ßu:</strong></p>
            <ol style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li>Ch·ªçn ngu·ªìn t√†i li·ªáu ∆∞a th√≠ch</li>
                <li>T·∫£i l√™n file ho·∫∑c c·∫•u h√¨nh repository/th∆∞ m·ª•c</li>
                <li>X·ª≠ l√Ω t√†i li·ªáu c·ªßa b·∫°n</li>
                <li>B·∫Øt ƒë·∫ßu ƒë·∫∑t c√¢u h·ªèi!</li>
            </ol>
            <br>
            <p><strong>Repository M·∫∑c ƒê·ªãnh:</strong><br>
            <code>https://github.com/Jennifer1907/Time-Series-Team-Hub/tree/main/assets/pdf</code></p>
            <br>
            <p><strong>T√≠nh NƒÉng N·ªïi B·∫≠t:</strong></p>
            <ul style='text-align: left; max-width: 500px; margin: 0 auto;'>
                <li>‚ú® H·ªó tr·ª£ ƒëa ƒë·ªãnh d·∫°ng (PDF, Word, Excel)</li>
                <li>üöÄ Kho vector FAISS cho t√¨m ki·∫øm t∆∞∆°ng t·ª± nhanh</li>
                <li>üáªüá≥ T·ªëi ∆∞u cho ti·∫øng Vi·ªát</li>
                <li>üîÑ Nhi·ªÅu ph∆∞∆°ng th·ª©c nh·∫≠p li·ªáu</li>
                <li>üí¨ Giao di·ªán tr√≤ chuy·ªán gi·ªëng ChatGPT</li>
                <li>üéØ Ph·∫£n h·ªìi nh·∫≠n th·ª©c ng·ªØ c·∫£nh</li>
                <li>üîë Kh√¥ng c·∫ßn API Key - Ho·∫°t ƒë·ªông offline!</li>
                <li>üåê S·ª≠ d·ª•ng RAG prompt template t·ª´ LangChain Hub</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()